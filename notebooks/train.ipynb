{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:09.748894Z","iopub.status.busy":"2024-08-12T11:15:09.748215Z","iopub.status.idle":"2024-08-12T11:15:23.937868Z","shell.execute_reply":"2024-08-12T11:15:23.936799Z","shell.execute_reply.started":"2024-08-12T11:15:09.748852Z"},"trusted":true},"outputs":[],"source":["!pip install requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:23.940175Z","iopub.status.busy":"2024-08-12T11:15:23.939863Z","iopub.status.idle":"2024-08-12T11:15:23.946899Z","shell.execute_reply":"2024-08-12T11:15:23.946016Z","shell.execute_reply.started":"2024-08-12T11:15:23.940148Z"},"trusted":true},"outputs":[],"source":["import os\n","# your wandb key for experiment tracking\n","os.environ[\"WANDB_API_KEY\"] = \"\"\n","# your Huggingface hub API key for saving the model and tokenizer\n","hf_token= \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:23.948191Z","iopub.status.busy":"2024-08-12T11:15:23.947929Z","iopub.status.idle":"2024-08-12T11:15:27.145260Z","shell.execute_reply":"2024-08-12T11:15:27.144397Z","shell.execute_reply.started":"2024-08-12T11:15:23.948168Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","import wandb\n","login(hf_token)\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:27.149076Z","iopub.status.busy":"2024-08-12T11:15:27.148027Z","iopub.status.idle":"2024-08-12T11:15:27.154408Z","shell.execute_reply":"2024-08-12T11:15:27.153499Z","shell.execute_reply.started":"2024-08-12T11:15:27.149043Z"},"trusted":true},"outputs":[],"source":["CONFIG = {\n","    'batch_size' : 32,\n","    'lr' : 1e-4,\n","    'epochs': 10,\n","    'seed':42,\n","    'weight_decay':0.01,\n","    'model_name': 'google-t5/t5-small',\n","    'model_path': './hf_best_model',\n","    'tokenizer_path': './hf_tokenizer',\n","    'max_length': 32,\n","    'warmup_ratio':0.2,\n","    'run_name':'baseline'\n","    \n","}\n","\n","\n","\n","SRC_LANG = \"dyu\"\n","TRG_LANG = \"fr\"\n","HF_USERNAME = \"\" # replace with HuggingFace hub username\n","HF_REPO_NAME = \"\" # replace with HuggingFace repo name\n","CHARS_TO_REMOVE_REGEX = '[!\"&\\(\\),-./:;=?+.\\n\\[\\]]'\n","PREFIX = \"translate Dyula to French: \"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:27.155829Z","iopub.status.busy":"2024-08-12T11:15:27.155560Z","iopub.status.idle":"2024-08-12T11:15:44.810506Z","shell.execute_reply":"2024-08-12T11:15:44.809725Z","shell.execute_reply.started":"2024-08-12T11:15:27.155799Z"},"trusted":true},"outputs":[],"source":["import re\n","import evaluate\n","import numpy as np\n","from datasets import load_dataset\n","\n","\n","\n","def remove_special_characters(text):\n","    text = re.sub(CHARS_TO_REMOVE_REGEX, \" \", text.lower())\n","    return text.strip()\n","\n","def clean_text(batch):\n","    batch[\"translation\"][SRC_LANG] = remove_special_characters(batch[\"translation\"][SRC_LANG])\n","    batch[\"translation\"][TRG_LANG] = remove_special_characters(batch[\"translation\"][TRG_LANG])\n","    return batch\n","\n","def preprocess_function(examples):\n","    inputs = [PREFIX + example[SRC_LANG] for example in examples[\"translation\"]]\n","    labels = [example[TRG_LANG] for example in examples[\"translation\"]]\n","    \n","    model_inputs = tokenizer(inputs,max_length=CONFIG['max_length'], truncation=True)\n","    labels = tokenizer(text_target=labels, max_length=CONFIG['max_length'], truncation=True)\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n","\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","        \n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {\"bleu\": result[\"score\"]}\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:44.812690Z","iopub.status.busy":"2024-08-12T11:15:44.811905Z","iopub.status.idle":"2024-08-12T11:15:49.410933Z","shell.execute_reply":"2024-08-12T11:15:49.409880Z","shell.execute_reply.started":"2024-08-12T11:15:44.812653Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline,AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments, GenerationConfig\n","\n","model_name = CONFIG['model_name']\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:49.412712Z","iopub.status.busy":"2024-08-12T11:15:49.412346Z","iopub.status.idle":"2024-08-12T11:15:49.418132Z","shell.execute_reply":"2024-08-12T11:15:49.417053Z","shell.execute_reply.started":"2024-08-12T11:15:49.412679Z"},"trusted":true},"outputs":[],"source":["GEN_CONFIG = {\n","    \"do_sample\": False,\n","    \"max_new_tokens\": 32,\n","    \"temperature\": 1.0,\n","    'decoder_start_token_id': model.config.decoder_start_token_id\n","}\n","gen_config = GenerationConfig(**GEN_CONFIG)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:49.419941Z","iopub.status.busy":"2024-08-12T11:15:49.419590Z","iopub.status.idle":"2024-08-12T11:15:57.022136Z","shell.execute_reply":"2024-08-12T11:15:57.021408Z","shell.execute_reply.started":"2024-08-12T11:15:49.419909Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"uvci/Koumankan_mt_dyu_fr\")\n","dataset = dataset.map(clean_text)\n","dataset = dataset.map(preprocess_function, batched=True)\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n","metric = evaluate.load(\"sacrebleu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:57.023714Z","iopub.status.busy":"2024-08-12T11:15:57.023110Z","iopub.status.idle":"2024-08-12T11:15:57.028875Z","shell.execute_reply":"2024-08-12T11:15:57.028026Z","shell.execute_reply.started":"2024-08-12T11:15:57.023688Z"},"trusted":true},"outputs":[],"source":["# Prepare datasets\n","train_dataset = dataset[\"train\"]\n","val_dataset = dataset[\"validation\"]\n","test_dataset = dataset['test']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T11:15:57.031644Z","iopub.status.busy":"2024-08-12T11:15:57.031366Z"},"trusted":true},"outputs":[],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir = './results',\n","    num_train_epochs=CONFIG['epochs'],\n","    per_device_train_batch_size=CONFIG['batch_size'],\n","    per_device_eval_batch_size=CONFIG['batch_size'],\n","    learning_rate=CONFIG['lr'],\n","    warmup_ratio=CONFIG['warmup_ratio'],\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_steps = 10,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"bleu\",\n","    push_to_hub=True,\n","    gradient_accumulation_steps=4,\n","    predict_with_generate=True,\n","    run_name=CONFIG['run_name'],\n","    hub_model_id = f\"{HF_USERNAME}/{HF_REPO_NAME}\",\n","    generation_config=gen_config\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics= compute_metrics,\n",")\n","\n","trainer.train()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
